{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-11 09:49:42.916742\n",
      "特征工程成功\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "from threading import Timer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import logging.handlers\n",
    "from sqlalchemy import create_engine\n",
    "from bmqb.feature_engineer import *\n",
    "from model_package import logit_ensemble, get_features, model_xgb\n",
    "\n",
    "# 原始数据\n",
    "path1 = \"/home/baowu/code/model/synthesis/feature_bw_all.csv\"\n",
    "# 全期特征的logit参数\n",
    "path2 = \"/home/llw/model_file/logit/params_all.csv\"\n",
    "# 6月-9月特征的logit参数\n",
    "path3 = \"/home/llw/model_file/logit/params_part.csv\"\n",
    "# 6月-9月的uid文件\n",
    "path4 = \"/home/llw/model_file/logit/features_sas.csv\"\n",
    "# 最新zk分\n",
    "path5 = \"/home/llw/model_file/logit/zk_v_3_4_without_zm.csv\"\n",
    "# 日志文件\n",
    "LOG_FILE = 'model.log'\n",
    "\n",
    "# 开始时间\n",
    "startDate = datetime.timedelta(seconds=10)\n",
    "# 数据库导出的表名称\n",
    "db_sheet = 'model_llw'\n",
    "# 处理数据时，为防止数据不同步（91查出来了，芝麻还没查出来等等），设置的线程延时处理（单位为秒）\n",
    "timer_feature_engineer = 3600  # 单位s\n",
    "# 每隔多长时间检测一下新数据\n",
    "data_catch_interval = 15  # 单位分钟\n",
    "handler = logging.handlers.RotatingFileHandler(LOG_FILE, maxBytes=1024 * 1024, backupCount=5)  # 实例化handler\n",
    "fmt = '%(asctime)s - %(filename)s:%(lineno)s - %(name)s - %(message)s'\n",
    "formatter = logging.Formatter(fmt)  # 实例化formatter\n",
    "handler.setFormatter(formatter)  # 为handler添加formatter\n",
    "logger = logging.getLogger('llw')  # 获取名为tst的logger\n",
    "logger.addHandler(handler)  # 为logger添加handler\n",
    "logger.setLevel(logging.DEBUG)\n",
    "zm_list = ['zm_hit_num','zmxyScore','zmxyIvsScore','zk_v_3_4','one_hot_V2_V_PH_CN_MA_UL90D',\n",
    "                                  'one_hot_V3_V_BC_CN_MA_UL180D','one_hot_F1_have_F1','one_hot_V2_V_PH_CN_MA_UL30D',\n",
    "                                  'one_hot_V3_V_BC_CN_MA_UM360D','one_hot_F1_None_F1','one_hot_F1_not_match']\n",
    "engine_1 = create_engine(\n",
    "    'mysql+pymysql://ro:cKqj4E3$K7GGeqs@nshd-slave-bi.mysql.rds.aliyuncs.com/paydayloan?charset=utf8',\n",
    "    echo=False, pool_size=20, max_overflow=0)\n",
    "engine_2 = create_engine(\n",
    "    'mysql+pymysql://riskcontrol:tuLwJ3G6FLwR6t4A@nshd-risk.mysql.rds.aliyuncs.com/riskcontrol?charset=utf8',\n",
    "    echo=False)\n",
    "\n",
    "zm_list = ['zm_hit_num','zmxyScore','zmxyIvsScore','zk_v_3_4','one_hot_V2_V_PH_CN_MA_UL90D','one_hot_V3_V_BC_CN_MA_UL180D',\n",
    " 'one_hot_F1_have_F1','one_hot_V2_V_PH_CN_MA_UL30D','one_hot_V3_V_BC_CN_MA_UM360D','one_hot_F1_None_F1','one_hot_F1_not_match']\n",
    "\n",
    "# features = get_features.get_features_part(传入dataframe)%输出在6月到9月之间的特征\n",
    "if os.path.exists(path2) == False:\n",
    "    features = pd.read_csv(path1, index_col=None)\n",
    "    del features['zk_v_3_4']\n",
    "    zk_Score = pd.read_csv(path5, index_col=None)\n",
    "    zk_Score.rename(columns = {\"zkScore\":\"zk_v_3_4\"},inplace=True)\n",
    "    features = pd.merge(features,zk_Score,how = 'left',on = 'uid')\n",
    "    features2 = get_features.get_features_all(features)\n",
    "    features2 = pd.merge(features2, features[['uid', 'label']], how='inner', on='uid')\n",
    "    print(features2.shape)\n",
    "    features2 = features2[[ii for ii in features2.columns if ii not in zm_list]]\n",
    "    print(features2.shape)\n",
    "    params_all = logit_ensemble.get_params(features2)  # 此步骤会打印模型ks和auc值，输出ks+auc最高的模型参数\n",
    "    params_all.to_csv(path2, index=None)\n",
    "    del features2\n",
    "    del features\n",
    "    del zk_Score\n",
    "else:\n",
    "    params_all = pd.read_csv(path2, index_col=None)\n",
    "logger.info('succeed loading para model1!')\n",
    "if os.path.exists(path3) == False:\n",
    "    features = pd.read_csv(path1, index_col=None)\n",
    "    del features['zk_v_3_4']\n",
    "    zk_Score = pd.read_csv(path5, index_col=None)\n",
    "    zk_Score.rename(columns = {\"zkScore\":\"zk_v_3_4\"},inplace=True)\n",
    "    features = pd.merge(features,zk_Score,how = 'left',on = 'uid')\n",
    "    uid = pd.read_csv(path4, index_col=None)\n",
    "    features = pd.merge(uid[['uid']], features, how='left', on='uid')\n",
    "    print(features.shape)\n",
    "    features3 = get_features.get_features_part(features)\n",
    "    features3 = pd.merge(features3, features[['uid', 'label']], how='inner', on='uid')\n",
    "    print(features3.shape)\n",
    "    features3 = features3[[i for i in features3.columns if i not in zm_list]]\n",
    "    print(features3.shape)\n",
    "    params_part = logit_ensemble.get_params(features3)  # 此步骤会打印模型ks和auc值，输出ks+auc最高的模型参数\n",
    "    params_part.to_csv(path3, index=None)\n",
    "    del features3\n",
    "    del features\n",
    "    del uid\n",
    "    del zk_Score\n",
    "else:\n",
    "    params_part = pd.read_csv(path3, index_col=None)\n",
    "\n",
    "logger.info('succeed loading para model2!')\n",
    "\n",
    "\n",
    "def run_Task(uid):\n",
    "    try:\n",
    "        u = model(uid)\n",
    "        data = u.features\n",
    "        logger.info('succeed: feature engineering')\n",
    "    except:\n",
    "        logger.debug('mistake: feature engineering')\n",
    "        return\n",
    "    try:\n",
    "        data.to_csv('data_tmp.csv', index=None)\n",
    "        data = pd.read_csv('data_tmp.csv', index_col=None)\n",
    "        logger.info('succeed: transform object to ndarray')\n",
    "    except:\n",
    "        logger.debug('mistake: transform object to ndarray')\n",
    "        return\n",
    "    try:\n",
    "        features_logit_all = get_features.get_features_all(data)  # 输出在所有时间段内的特征\n",
    "        features_logit_part = get_features.get_features_part(data)  # 输出在6月到9月之间的特征\n",
    "        features_logit_all = features_logit_all[[i for i in features_logit_all.columns if i not in zm_list]]\n",
    "        features_logit_part = features_logit_part[[i for i in features_logit_part.columns if i not in zm_list]]\n",
    "    except:\n",
    "        logger.debug('mistake: woe transform')\n",
    "        return\n",
    "    try:\n",
    "        logit_score_all = logit_ensemble.predict(features_logit_all, params_all)\n",
    "        logit_score_part = logit_ensemble.predict(features_logit_part, params_part)\n",
    "        df = data[['uid']]\n",
    "        df['updatedAt'] = [datetime.datetime.now() for i in range(len(data))]\n",
    "        df['logit_part_time'] = list(logit_score_part['score'])\n",
    "        df['logit_all_time'] = list(logit_score_all['score'])\n",
    "    except:\n",
    "        logger.debug('mistake: logit')\n",
    "        return\n",
    "    try:\n",
    "        logger.info('succeed: logit')\n",
    "        xgb_score = model_xgb.Three_cobblers(data)\n",
    "        df = pd.merge(df, xgb_score, how='left', on='uid')\n",
    "        logger.info('succeed: xgb')\n",
    "    except:\n",
    "        logger.debug('mistake: xgb')\n",
    "        return\n",
    "    try:\n",
    "        df.to_sql(db_sheet, engine_2, chunksize=100, if_exists='append')\n",
    "        logit_score_all.to_sql('logit_score_all', engine_2, chunksize=100, if_exists='append')\n",
    "        logit_score_part.to_sql('logit_score_part', engine_2, chunksize=100, if_exists='append')\n",
    "        logger.info('Victory! %s', uid)\n",
    "    except:\n",
    "        logger.debug('mistake: dataframe to_sql')\n",
    "        return\n",
    "\n",
    "def queryFun(time_start,time_end):\n",
    "    sql = '''select userId,status from eva_riskcontrol_audits where status in ('approved','rejected','pending') and createdAt >= ''' + str(int(time_start)) + ''' and createdAt <= ''' + str(int(time_end))\n",
    "#     sql = '''select userId,status from eva_riskcontrol_audits where createdAt >= ''' + str(int(time_start)) + ''' and createdAt < ''' + str(int(time_end))\n",
    "    print(sql)\n",
    "    uid_list = pd.read_sql(sql, engine_1)['userId']\n",
    "    uid_list = list(uid_list)\n",
    "    logger.info('new user number %s', len(uid_list))\n",
    "    if len(uid_list) > 0:\n",
    "        logger.info('new user uid: %s', uid_list)\n",
    "        try:\n",
    "            run_Task(uid_list)\n",
    "        except:\n",
    "            logger.debug('something wrong in run_Task')\n",
    "def timerFun(sched_Timer):\n",
    "    while True:\n",
    "        now = datetime.datetime.now() - startDate\n",
    "        # print(sched_Timer, now)\n",
    "        if now > sched_Timer:\n",
    "            logger.info('start working!')\n",
    "            time_15min_ago = sched_Timer - datetime.timedelta(minutes=data_catch_interval)\n",
    "            timestamp = time.mktime(time_15min_ago.timetuple())\n",
    "            timestamp2 = time.mktime(sched_Timer.timetuple())\n",
    "            Timer(timer_feature_engineer, queryFun, (timestamp, timestamp2,)).start()\n",
    "            sched_Timer = sched_Timer + datetime.timedelta(minutes=data_catch_interval)\n",
    "\n",
    "# sched_Timer = datetime.datetime.now() + datetime.timedelta(seconds = 10)\n",
    "sched_Timer = datetime.datetime.now() - startDate\n",
    "print(sched_Timer)\n",
    "timerFun(sched_Timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
